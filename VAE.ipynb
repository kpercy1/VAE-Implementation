{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR2wBH7bGZhK"
   },
   "source": [
    "# VAE Theory\n",
    "\n",
    "All theory is from https://arxiv.org/abs/1606.05908.\n",
    "\n",
    "Notation:\n",
    "- $X$ is a data point in our dataset\n",
    "- $z$ is the latent representation of a data point\n",
    "- $\\theta$ is the parameters for our model, which will be a distribution for $P(X|z;\\theta)$. Specifically, our model is a mapping from the latent representation to a data point.\n",
    "- $D$ is our entire dataset, so $X\\in D$.\n",
    "<!-- \n",
    "- $f(z;\\theta)$ is a map from latent variables z to a point estimate for a data point, X.)\n",
    "<> - $Q(z|X)$ is a \"surrogate\" distribution to approximate the probability $P(z|X)$. Assuming we choose that Q(z|X) is normal, then $\\mu(X;\\phi)$ and $\\Sigma(X;\\phi)$ are the mean and variance, respectively.\n",
    "-->\n",
    "\n",
    "\n",
    "Explanation\n",
    "- We wish to maximising the probability of our data under our model,\n",
    "\\begin{equation}\n",
    "P(X) = \\int P(X|z; \\theta) P(z)dz.\n",
    "\\end{equation}\n",
    "- When $X$ is continuous, it is common to use a normal distribution for our model:\n",
    "$$P(X|z; \\theta) = N(f(z;\\theta), \\sigma^2 I).$$\n",
    "Here, $f(z;\\theta)$ is our point estimate for a mapping from the latent representation to the data points, i.e. $f:\\mathcal{Z} \\times \\Theta\\rightarrow \\mathcal{X}$, where any $z\\in \\mathcal{Z}$, $\\theta \\in \\Theta$ and $X \\in \\mathcal{X}$. Also, $\\sigma^2$ is a hyperparameter of the model, and is set beforehand.\n",
    "- We say that the samples of $z$ are from a $N(0, I)$ distribution, so $f(z; \\theta)$ is left with the responsiblity of first converting these normal samples into latent variables which are more representative/useful. This uses the fact that any distribution in $d$ dimensions can be generated by taking a set of $d$ variables that are normally distributed and mapping them through a sufficiently complicated function (this is an extension of inverse transform sampling).\n",
    "- To allow sufficient flexibility, $f(z;\\theta)$ is usually a multi-layer neural network. This allows us to learn a map from $z\\sim N(0, \\sigma^2 I)$ to something which \"looks like\" a data point, $X$. \n",
    "- A naive approach would be to sample $z_1, ..., z_n$ for very large $n$, then approximate our model evidence as $P(X) \\approx \\frac{1}{n} \\sum_{i=1}^n P(X|z_i; \\theta)$. From here we could use gradient descent to optimise $f(z; \\theta)$ by maximising $P(X)$. The problem is that in higher dimensional space, $n$ might have to be extremely large before we get an accurate estimate. This is because usually, for most $z$, $P(X|z)$ will be nearly zero. The key idea of Variational Autoencoders is to attempt to sample values of $z$ that are likely to have produced $X$, and then compute $P(X)$ just from these...\n",
    "- The definition of KL-divergence is\n",
    "\\begin{equation}\n",
    "D_{KL}(P||Q) = \\int P(x) \\log \\left(\\frac{P(x)}{Q(x)}\\right)dx.\n",
    "\\end{equation}\n",
    "Equivalently,\n",
    "\\begin{equation}\n",
    "D_{KL}(P||Q) = \\mathbb{E}_{X\\sim P} \\left[ \\log\\left(\\frac{P(x)}{Q(x)}\\right)\\right] = \\mathbb{E}_{X\\sim P} \\left[ \\log P(x) - \\log Q(x) \\right].\n",
    "\\end{equation}\n",
    "- In VAEs, we explained earlier that we want to sample the values of $z$ which are likely to have produced any particular data point, $X$. We use a \"surrogate\" distribution to approximate $P(z|X)$, $Q(z|X)$. Then, the KL-divergence between our surrogate distribution $Q(z|X)$ and the probability of latent variables in a particular data point, $P(z|X)$ is given by\n",
    "\\begin{equation*}\n",
    "D_{KL}(Q(z|X) || P(z|X)) = \\mathbb{E}_{z\\sim Q} \\left[ \\log Q(z|X) - \\log P(z|X) \\right].\n",
    "\\end{equation*}\n",
    "Now we can apply Bayes Rule:\n",
    "\\begin{align}\n",
    "P(z|X) &= \\frac{P(X|z) P(z)}{P(X)} \\implies D_{KL}(Q(z|X) || P(z|X))\\\\ \n",
    "&= \\mathbb{E}_{z\\sim Q} \\left[ \\log Q(z|X) - \\log \\left( \\frac{P(X|z) P(z)}{P(X)}\\right)\\right]\\\\\n",
    "&= \\mathbb{E}_{z\\sim Q} \\left[ \\log \\left( \\frac{Q(z|X)}{P(z)}\\right) - \\log P(X|z) \\right] + \\log P(X)\\\\\n",
    "&= D_{KL}(Q(z|X) || P(z)) - \\mathbb{E}_{z\\sim Q}\\left[ \\log P(X|z) \\right] + \\log P(X).\\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\therefore \\log P(X) - F_{KL}(Q(z|X) || P(z)) = \\mathbb{E}_{z\\sim Q}\\left[ \\log P(X|z)\\right] - D_{KL}(Q(z|X) || P(z))\n",
    "\\end{equation*}\n",
    "\n",
    "We cannot compute $D_{KL}(Q(z|X) || P(z|X))$ without knowing $P(z|X)$, but a property of KL-divergence is that it is non-negative. Therefore, our expression becomes\n",
    "\\begin{equation*}\n",
    "\\log P(X) \\geq \\mathbb{E}_{z\\sim Q}\\left[ \\log P(X|z)\\right] - D_{KL}(Q(z|X) || P(z)).\n",
    "\\end{equation*}\n",
    "The LHS is called the evidence, hence the RHS is called the \"Evidence Lower BOund\" (ELBO). We wish to maximies the evidence (as this corresponds to the observed data being likely under our model), so in VAEs we do this by maximising the RHS and treating $D_{KL}(Q(z|X) || P(z|X))$ as an error term.\n",
    "- Typically, we set our surrogate distribution as $Q(z|X) \\sim N(\\mu(X; \\phi), \\Sigma(X; \\phi))$. In practice, $\\mu(X; \\phi)$ and $\\Sigma(X;\\phi)$ are again obtained using neural networks, and these are maps from a data point $X$ to the estimated mean and variance for the latent variables, respectively. Hence, the parameters $\\phi$ are learned from the data. Note that $\\Sigma$ is constrained to be a diagonal matrix, as independence between components is necessary for computational tractibility and encourages disentanglement of latent variables.\n",
    "- In the ELBO, the term $D_{KL}(Q(z|X) || P(z))$ is a KL-divergence between multivariate Gaussian distributions, hence a closed form expression for the KL-divergence is known. In our case, \n",
    "\\begin{align}\n",
    "D_{KL}(Q(z|X) || P(z)) &= D_{KL}(N(\\mu(X), \\Sigma(X)) || N(0, I))\\\\\n",
    "&= \\frac{1}{2}\\left( \\text{trace}(\\Sigma(X)) + (\\mu(X))^T (\\mu(X)) - k - \\log \\text{det}(\\Sigma(X))\\right)\n",
    "\\end{align}\n",
    "\n",
    "But, in the ELBO it is more difficult to compute the term $\\mathbb{E}_{z \\sim Q} \\left[ log P(X|z) \\right]$. One approach is to estimate this expectation by sampling many $z$, although this will be expensive. Instead, we can apply the idea from stochastic gradient descent and use a single sample of $z$ to approximate this expectation for a single data point, X. Then, our total loss (over the entire dataset $D$) to minimise with stochastic gradient descent is\n",
    "\\begin{equation}\n",
    "\\mathbb{E}_{X\\sim D} \\left[ \\mathbb{E}_{z \\sim Q} \\left[ \\log P(X|z) \\right] - D_{KL} (Q(z|X) || P(z)) \\right].\n",
    "\\end{equation}\n",
    "We estimate the gradient of this by averaging the gradient of\n",
    "\\begin{equation}\n",
    "\\log P(X|z) - D_{KL}(Q(z|X) || P(z))\n",
    "\\end{equation}\n",
    "for an arbitrary number of samples of $z$ and $X$. The result will converge to the overall gradient (for all $X$, $z$).\n",
    "\n",
    "- But, the issue with the above gradient estimate is that we can't actually backpropogate through $\\mathbb{E}_{z\\sim Q} \\left[ \\log P(X|z) \\right]$, as the expectation $\\mathbb{E}_{z \\sim Q} \\left[ \\cdot \\right]$ depends on $\\phi$. Specifically, in general $\\triangledown_{\\phi} \\mathbb{E}_{z\\sim Q} \\left[ \\log P(X|z) \\right] \\neq \\mathbb{E}_{z\\sim Q} \\left[ \\triangledown_{\\phi} \\log P(X|z) \\right]$. In integral form,\n",
    "\\begin{align}\n",
    "\\triangledown_{\\phi} \\mathbb{E}_{z\\sim Q} \\left[ \\log P(X|z) \\right] &= \\int_z \\triangledown_{\\phi} ( Q(z|X) \\log P(X|z) ) dz\\\\\n",
    "&= \\int_z \\triangledown_{\\phi} (Q(z|X)) \\log P(X|z)dz + \\int_z Q(z|X) \\triangledown_{\\phi} ( \\log P(X|z) ) dz\\\\\n",
    "&= \\int_z \\triangledown_{\\phi} (Q(z|X)) \\log P(X|z)dz + \\mathbb{E}_{z \\sim Q} \\left[ \\triangledown_{\\phi} (\\log P(X|z) ) \\right].\n",
    "\\end{align}\n",
    "\n",
    "We get around this issue using the reparametrisation trick. We instead convert the random sampling into a (stochastic) input, and then write $Q(z|X)$ as a deterministic function of these stochastic inputs. For example, when $Q(z|X)\\sim N(\\mu(X; \\phi), \\Sigma(X; \\phi))$ can be written as \n",
    "$$Q(z|X) = \\mu(X; \\phi) + (\\Sigma(X; \\phi))^{\\frac{1}{2}} \\cdot \\epsilon,$$ \n",
    "where $\\epsilon \\sim N(0, I)$. In general, we want to sample from $Q(z|X)$ by evaluating a function $h(\\nu, X)$, where $\\nu$ is noise from a distribution that is not learned (i.e. has fixed inputs that don't depend on $\\phi$). Also, $h$ must be continuous in $X$ so that we can backpropogate through it. \n",
    "\n",
    "Things to estimate in VAE:\n",
    "- $f(z; \\theta)$, neural network. Maps $z$ to $X$.\n",
    "- $\\mu(X; \\phi)$ and $\\Sigma(X; \\phi)$, neural network. Parameters of the surrogate $Q(z|X)$ for $P(z|X)$. $\\mu$ maps the data point $X$ to a point estimate of the mean for the latent variables $z$, and $\\Sigma$ maps $X$ to the estimated variance for $z$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first apply to the MNIST Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "GcKNKGJFGSO1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "# Transform: Normalize and flatten\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #Shape: (1, 28, 28)\n",
    "    transforms.Normalize((0.5,), (0.5,)), # normalize to [-1, 1]\n",
    "    transforms.Lambda(lambda x: x.view(-1)) #flatten to (784,)\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of object 1: <class 'torch.Tensor'>\n",
      "size of tensor:  torch.Size([4, 784])\n",
      "type of object 2: <class 'torch.Tensor'>\n",
      "size of tensor:  torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    for i, thing in enumerate(batch):\n",
    "        print(f\"type of object {i+1}: {type(thing)}\")\n",
    "        if type(thing) == torch.Tensor:\n",
    "            print(f\"size of tensor: \", thing.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the dataloaders have the first item as a tensor containing the images, while the second item is the digit. Both are tensors, and the first dimension is used for the batch. The final two dimensions are for the x and y coordinate for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def image_reshape(images):\n",
    "    \"\"\"\n",
    "    Function to resize images from the dataloaders.\n",
    "\n",
    "    Inputs:\n",
    "    - images: tensor containing a batch of images.\n",
    "    Shape: (batch_size, num_observed_vars)\n",
    "\n",
    "    Outputs:\n",
    "    - images: tensor containing a batch of resized images.\n",
    "    Shape: (batch_size, image_height, image_width, image_channels)\n",
    "    \"\"\"\n",
    "\n",
    "    images = images.reshape((-1, 1, 28, 28))\n",
    "    return images\n",
    "\n",
    "for (images, digits) in train_loader:\n",
    "    images = image_reshape(images)\n",
    "    print(images.shape)\n",
    "    plt.imshow(images[0, 0, :, :], cmap='gray')\n",
    "    plt.title(\"28x28 Tensor Image\")\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "F1ZcpDhMIrSt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functions generated\n"
     ]
    }
   ],
   "source": [
    "#Some functions to compute loss\n",
    "\n",
    "def multivariate_normal_KL_divergence(mu_1, sigma_1, mu_2, sigma_2):\n",
    "  \"\"\"\n",
    "  Function to compute KL divergence between two multivariate normal distributions. \n",
    "  This has closed form, as shown in https://arxiv.org/pdf/1606.05908.\n",
    "\n",
    "  This function is NOT vectorised.\n",
    "\n",
    "  Inputs:\n",
    "  - mu_1: a vector of means for distribution 1.\n",
    "  - sigma_1: a covariance matrix for distribution 1.\n",
    "  - mu_2: a vector of means for distribution 2.\n",
    "  - sigma_2: a covariance matrix for distribution 2.\n",
    "\n",
    "  Outputs:\n",
    "  - KL_divergence: computed KL divergence, D(distribution_1, distribution_2).\n",
    "  \"\"\"\n",
    "\n",
    "  #Initialise variables\n",
    "  sigma_2_inv = torch.linalg.inv(sigma_2)\n",
    "  k = len(mu_1)\n",
    "\n",
    "  #Compute KL-divergence\n",
    "  KL_divergence = 1/2 * ( torch.trace(sigma_2_inv @ sigma_1) + (mu_2 - mu_1).T @ sigma_2_inv @ (mu_2 - mu_1) - k + torch.log(torch.linalg.det(sigma_2) / torch.linalg.det(sigma_1)))\n",
    "\n",
    "  return KL_divergence\n",
    "\n",
    "def normal_KL_divergence_from_standard_normal(mu, sigma):\n",
    "  \"\"\"\n",
    "  Function to compute KL divergence between the given normal distribution and the standard normal\n",
    "  distribution, N(0, I). This is equivalent to multivariate_normal_KL_divergence(), except it is\n",
    "  more efficient when the second distribution is the standard normal. Closed form is obtained from\n",
    "  https://arxiv.org/pdf/1606.05908.\n",
    "\n",
    "  This function is vectorised.\n",
    "\n",
    "  Inputs:\n",
    "  - mu: a vector of means for the distribution.\n",
    "  Shape: (*, n_vars)\n",
    "  - sigma: a covariance matrix for the distribution.\n",
    "  Shape: (*, n_vars, n_vars)\n",
    "\n",
    "  Outputs:\n",
    "  - KL_divergence: computed KL divergence, D(distribution_1, N(0, I)).\n",
    "  Shape: (*)\n",
    "  \"\"\"\n",
    "\n",
    "  #Initialise variables\n",
    "  k = mu.shape[-1]\n",
    "\n",
    "  #Compute traces (vectorised)\n",
    "  #Shape: (batch_size, n_vars)\n",
    "  sigma_traces = sigma.diagonal(dim1=-2, dim2=-1).sum(-1)\n",
    "\n",
    "  #Compute KL-divergence\n",
    "  KL_divergence = 1/2 * ( sigma_traces + torch.sum(mu ** 2, dim = -1) - k - torch.linalg.slogdet(sigma)[1] )\n",
    "\n",
    "  return KL_divergence\n",
    "\n",
    "def extract_vector_X(images):\n",
    "  \"\"\"\n",
    "  Function to resize a batch of images in the dataloader to tensors of shape \n",
    "  (batch_size, n_observed_vars). This is necessary since X is assumed to be from a multivariate\n",
    "  normal distribution.\n",
    "\n",
    "  Inputs:\n",
    "  - images: a tensor for a batch of images from the dataloader. \n",
    "  Shape: (batch_size, 1, n_rows, n_cols)?\n",
    "\n",
    "  Ouptuts: \n",
    "  - X: a resized tensor for a batch of images.\n",
    "  Shape: (batch_size, n_rows, n_cols)\n",
    "  \"\"\"\n",
    "\n",
    "  #Resize tensors\n",
    "  X = torch.squeeze(images.flatten(start_dim = -2))\n",
    "\n",
    "  return X\n",
    "  \n",
    "def loss_per_batch(X, z, Q_mu, Q_sigma, P_mu, P_sigma):\n",
    "  \"\"\"\n",
    "  Function to compute loss over entire batch. In a VAE, this is the negative of the evidence lower bound (ELBO).\n",
    "  We wish to maximise the ELBO, hence we minimise the negative ELBO.\n",
    "\n",
    "  Note that we assume that the latent variables z are drawn from a multivariate standard normal dstribution, N(0, I).\n",
    "\n",
    "  Here, \"P\" refers to our map from latent variables to data points, P(X|z).\n",
    "\n",
    "  Inputs:\n",
    "  - X: tensor containing the observed data points for a batch.\n",
    "  Shape: (batch_size, n_observed_vars)\n",
    "  - z: tensor containing the latent variables corresponding to the given observed data points.\n",
    "  Note that we allow multiple latent variable samples for a single data point, as z_batch_size \n",
    "  does not need to be 1.\n",
    "  Shape: (batch_size, z_batch_size, n_latent_vars)\n",
    "  - Q_mu: vector of means for our normal surrogate distribution, Q(z|X). \n",
    "  Shape: (batch_size, n_latent_vars)\n",
    "  - Q_sigma: covariance matrix for our normal surrogate distribution, Q(z|X). \n",
    "  Shape: (batch_size, n_latent_vars, n_latent_vars)\n",
    "  - P_mu: vector of means for P. \n",
    "  Shape: (batch_size, z_batch_size, n_observed_vars)\n",
    "  - P_sigma: covariance matrix for P. \n",
    "  Shape: (batch_size, z_batch_size, n_observed_vars, n_observed_vars)\n",
    "\n",
    "  Outputs:\n",
    "  - loss: a float for the loss to be maximised \n",
    "  \"\"\"\n",
    "\n",
    "  #Initialise variables\n",
    "  #Number of latent and observed variables\n",
    "  n_observed = X.shape[-1]\n",
    "  n_latent = Q_mu.shape[-1]\n",
    "  #Distributions for P=P(X|z) and Q=Q(z|X)\n",
    "  P = torch.distributions.MultivariateNormal(P_mu, P_sigma)\n",
    "  Q = torch.distributions.MultivariateNormal(Q_mu, Q_sigma)\n",
    "\n",
    "  #Compute loss per data point\n",
    "  #Note that Pytorch should automatically implement the reparametrisation trick here.\n",
    "  P_log_likelihood = P.log_prob(X.reshape(batch_size, 1, n_observed).repeat(1, z_batch_size, 1))\n",
    "  KL_divergence = normal_KL_divergence_from_standard_normal(Q_mu, Q_sigma)\n",
    "  #Average log likelihood over all z samples\n",
    "  loss = - torch.mean(P_log_likelihood, dim = 1) + KL_divergence\n",
    "\n",
    "  return loss\n",
    "\n",
    "print(\"All functions generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for the Functions Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "normal_KL_divergence_from_standard_normal test.\n",
      "Expected value==Test Value: True.\n",
      "Manually-calculated value == Expected Value: True.\n",
      "Manually-calculated value == Test Value: True\n",
      "\n",
      "\n",
      "loss_per_batch test.\n",
      "Expected_value == Obtained_value: True.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "n_observed = 10\n",
    "n_latent = 5\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "Z_mu = torch.zeros(n_latent)\n",
    "Z_sigma = torch.eye(n_latent)\n",
    "Z = torch.distributions.MultivariateNormal(Z_mu, Z_sigma)\n",
    "\n",
    "Q_mu = Z.sample((batch_size,))\n",
    "Q_sigma = torch.diag_embed(torch.abs(Z.sample((batch_size,))))\n",
    "\n",
    "#Compute KL-divergence between Q and I manually\n",
    "Q = torch.distributions.MultivariateNormal(Q_mu, Q_sigma)\n",
    "expected_KL = torch.distributions.kl_divergence(Q, Z)\n",
    "test_KL = normal_KL_divergence_from_standard_normal(Q_mu, Q_sigma)\n",
    "manual_KL = torch.zeros((batch_size,))\n",
    "for i in range(batch_size):\n",
    "    manual_KL[i] = 1/2 * (torch.log(torch.linalg.det(Z_sigma) / torch.linalg.det(Q_sigma[i, :, :])) - n_latent + torch.trace(torch.linalg.inv(Z_sigma) @ Q_sigma[i, :, :]) + (Z_mu - Q_mu[i, :]).T @ torch.linalg.inv(Z_sigma) @ (Z_mu - Q_mu[i, :]))\n",
    "\n",
    "#Test 1: normal_KL_divergence_from_standard_normal()\n",
    "print(f\"\\n\\nnormal_KL_divergence_from_standard_normal test.\\nExpected value==Test Value: {torch.allclose(expected_KL, test_KL, atol=1e-5, rtol=1e-3)}.\\nManually-calculated value == Expected Value: {torch.allclose(manual_KL, expected_KL, atol=1e-5, rtol=1e-3)}.\\nManually-calculated value == Test Value: {torch.allclose(manual_KL, test_KL, atol=1e-5, rtol=1e-3)}\")\n",
    "\n",
    "#Test passed\n",
    "\n",
    "#Initialise variables\n",
    "z_batch_size = 3\n",
    "\n",
    "#Create new distribution, P=P(X|z)\n",
    "Z_mu = torch.zeros(n_observed)\n",
    "Z_sigma = torch.eye(n_observed)\n",
    "Z = torch.distributions.MultivariateNormal(Z_mu, Z_sigma)\n",
    "P_mu = Z.sample((batch_size, z_batch_size))\n",
    "P_sigma = torch.diag_embed(torch.abs(Z.sample((batch_size, z_batch_size))))\n",
    "P = torch.distributions.MultivariateNormal(P_mu, P_sigma)\n",
    "\n",
    "manual_P_log_likelihood = torch.zeros((batch_size, z_batch_size, n_latent))\n",
    "\n",
    "#Sample a single batch of X\n",
    "#In practice this would be conditioned on a sample of z from Q\n",
    "X = P.sample((1,)).squeeze()[:, 0, :]\n",
    "\n",
    "Z_mu = torch.zeros(n_latent)\n",
    "Z_sigma = torch.eye(n_latent)\n",
    "Z = torch.distributions.MultivariateNormal(Z_mu, Z_sigma)\n",
    "\n",
    "#Sample z from Q, then compute log-likelihood of X given z\n",
    "z = Q.rsample((z_batch_size,))\n",
    "manual_P_log_likelihood = P.log_prob(X.unsqueeze(1).repeat(1, z_batch_size, 1))\n",
    "manual_KL_divergence = torch.distributions.kl_divergence(Q, Z)\n",
    "\n",
    "#Average over all z samples\n",
    "manual_loss = -torch.mean(manual_P_log_likelihood, dim = 1) + manual_KL_divergence\n",
    "test_loss = loss_per_batch(X, z, Q_mu, Q_sigma, P_mu, P_sigma)\n",
    "\n",
    "#TEST 2: loss_per_batch\n",
    "print(f\"\\n\\nloss_per_batch test.\\nExpected_value == Obtained_value: {torch.allclose(manual_loss, test_loss, atol=1e-5, rtol=1e-3)}.\")\n",
    "#Test passed\n",
    "\n",
    "\n",
    "\n",
    "#TODO: Consider how we aggregate values. It will depend on whether testing or training, etc? Could use\n",
    "#an aggregate_values function? Or maybe just leave everything and then during training we can take the\n",
    "#sum, etc.\n",
    "\n",
    "\n",
    "#TODO: fix dimensions - do we want the distribution to only have a single mean? <-- NO, best to vectorise\n",
    "#over batch_size, then the number of samples in z_batch_size, right?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "We will use Optuna to find the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Neural Network Model\n",
    "class neural_network(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Create class for a neural network with a variable number of layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_sizes, n_inputs, n_outputs):\n",
    "        \"\"\"\n",
    "        Initialise the model and relevant hyperparameters\n",
    "\n",
    "        Inputs:\n",
    "        - hidden_sizes: a list containing the number of neurons in each layer in the neural network.\n",
    "        - n_inputs: the number of inputs to be produced by the neural network.\n",
    "        - n_outputs: the number of outputs to be produced by the neural network.\n",
    "        \"\"\"\n",
    "\n",
    "        super(neural_network, self).__init__()\n",
    "\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        #Create a ModuleList to hold the layers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        #Create layers of neural network\n",
    "        in_size = n_inputs\n",
    "        for out_size in hidden_sizes:\n",
    "            self.layers.append(torch.nn.Linear(in_size, out_size))\n",
    "            in_size = out_size #Update number of inputs for next layer\n",
    "        self.layers.append(torch.nn.Linear(in_size, n_outputs))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" \n",
    "        Establish how inputs move through the neural network. This is where we set the \n",
    "        activation function.\n",
    "\n",
    "        Inputs:\n",
    "        - X: tensor of inputs.\n",
    "        Shape: (batch_size, n_inputs)\n",
    "\n",
    "        Outputs:\n",
    "        - X: tensor of outputs.\n",
    "        Shape: (batch_size, n_outputs)\n",
    "        \"\"\"\n",
    "\n",
    "        for layer in self.layers:\n",
    "            X = torch.nn.functional.relu(layer(X))\n",
    "\n",
    "        return X\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    \"\"\"      \n",
    "    Create VAE model. The main goal is to estimate the following with neural networks:\n",
    "    - f = f(z; theta): this is a map from latent variables to a point estimate for X, as we assume that\n",
    "    P(X|z) has distribution N( f(z; theta), sigma^2*I ). \n",
    "    - mu = mu(X; phi) and sigma = sigma(X; phi): these parametrise Q(z|X), which we assume to have \n",
    "    distribution N( mu(X; phi), sigma(X; phi) ).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_observed, n_latent, f_hidden_sizes, Q_hidden_sizes, z_batch_size):\n",
    "        \"\"\"\n",
    "        Initialise the model and relevant hyperparameters\n",
    "\n",
    "        Inputs:\n",
    "        - n_observed: the number of observed variables\n",
    "        - n_latent: the number of latent variables\n",
    "        - f_hidden_sizes: a list for the number of hidden sizes in the neural network f(z; theta).\n",
    "        - Q_hidden_sizes: a list for the number of hidden sizes in the neural network for \n",
    "        the parameters of Q (mu(X; phi) and sigma(X; phi)).\n",
    "        - z_batch_size: the number of latent variables to sample per observed data point.\n",
    "\n",
    "        Notes:\n",
    "        - self.n_outputs depends on the number of latent and observed variables. \n",
    "        - self.log_sigma2 is a parameter of the model, as it is not specific to each data point\n",
    "        (homoscedastic variance). We use log variance, as then taking the exponential ensures varaince\n",
    "        is positive.\n",
    "        \"\"\"\n",
    "\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #Initialise hyperparameters\n",
    "        self.n_observed = n_observed\n",
    "        self.n_latent = n_latent\n",
    "        self.z_batch_size = z_batch_size\n",
    "\n",
    "        #Initialise log variance. Note that this will be optimised\n",
    "        self.log_sigma2 = torch.nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        #Initialise instances of neural networks.\n",
    "        #Recall that f maps z to X and Q maps X to z, so this determines the number of inputs and outputs.\n",
    "        #For Q, mu and sigma both have n_latent elements, hence the total outputs is 2*n_latent.\n",
    "        self.f_nn = neural_network(f_hidden_sizes, n_latent, n_observed)\n",
    "        self.Q_n_outputs = 2*n_latent\n",
    "        self.Q_nn = neural_network(Q_hidden_sizes, n_observed, self.Q_n_outputs)\n",
    "\n",
    "    def forward(self, inputs, skip_encode = False):\n",
    "        \"\"\"\n",
    "        Forward function for the VAE model. Here, we use Q to encode our data, then f to decode.\n",
    "\n",
    "        Inputs:\n",
    "        - inputs: depends on skip_encode (see below).\n",
    "        - skip_encode: a boolean which determines whether \"inputs\" are observed data points or latent\n",
    "        variables.\n",
    "        if skip_encode == False:\n",
    "            inputs is a tensor of observed data.\n",
    "            Shape: (batch_size, n_observed)\n",
    "        if skip_encode == True:\n",
    "            inputs is a tensor of latent variables.\n",
    "            Shape: (batch_size,  z_batch_size, n_latent)\n",
    "\n",
    "        Outputs:\n",
    "        - outputs: a tuple, where the elements depends on skip_encode.\n",
    "        if skip_encode == False:\n",
    "            - z: samples from Q, which represent likely latent variables corresponding to each observed\n",
    "            data point.\n",
    "            Shape: (batch_size, z_batch_size, n_latent)\n",
    "            - Q_mu & Q_sigma: tensors containing the mean and variance for our surrogate distribution, \n",
    "            Q=Q(z|X), respectively. \n",
    "            Shapes: (batch_size, n_latent) & (batch_size, n_latent, n_latent).\n",
    "            - P_mu & P_sigma: tensors containing the mean and variance for our decoder, P=P(X|z), \n",
    "            respectively. \n",
    "            Shapes: (batch_size, z_batch_size, n_observed) & (batch_size, z_batch_size, n_observed, n_observed).\n",
    "        if skip_encode == True:\n",
    "            - P_mu & P_simga: see above.\n",
    "\n",
    "        Note that point estimates for the reconstructed data is given by P_mu = f(z; theta).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        #Initialise variables\n",
    "        batch_size = inputs.shape[0]\n",
    "\n",
    "        if skip_encode == True:\n",
    "            #Relabel inputs\n",
    "            z = inputs\n",
    "\n",
    "        else:\n",
    "            #Relabel inputs\n",
    "            X = inputs\n",
    "\n",
    "            #Encode data as probability distributions\n",
    "            #Elements of variance matrix must be positive, so take exponential.\n",
    "            Q_parameters = self.Q_nn(X)\n",
    "            Q_mu = Q_parameters[:, 0:self.n_latent]\n",
    "            Q_sigma = torch.exp(Q_parameters[:, self.n_latent:])\n",
    "            Q_sigma =  torch.diag_embed(Q_sigma)\n",
    "\n",
    "            #Sample from Q to get encoded variables.\n",
    "            #Permute dimensions so that z has the intended shape: (batch_size, z_batch_size, n_latent)\n",
    "            Q = torch.distributions.MultivariateNormal(Q_mu, Q_sigma)\n",
    "            z = Q.rsample((self.z_batch_size,))\n",
    "            z = torch.movedim(z, 0, 1) \n",
    "\n",
    "        #Decode sampled latent variables.\n",
    "        #Here, f is the point estimate for X, i.e. it is our reconstructed observed data.\n",
    "        f = self.f_nn(z)\n",
    "        P_mu = f\n",
    "        P_sigma = torch.exp(self.log_sigma2) * torch.eye(self.n_observed)\n",
    "        #Reshape P_sigma\n",
    "        P_sigma = P_sigma.reshape(1, 1, self.n_observed, self.n_observed).repeat(batch_size, self.z_batch_size, 1, 1)\n",
    "\n",
    "        #Outputs depend on whether we skipped encoding or not\n",
    "        if skip_encode == True:\n",
    "            outputs = ( P_mu, P_sigma )\n",
    "        else: \n",
    "            outputs = ( z, Q_mu, Q_sigma, P_mu, P_sigma )\n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test function for VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_mu.shape: torch.Size([4, 7, 5]), Q_sigma.shape: torch.Size([4, 5]), z.shape: torch.Size([4, 5, 5]), P_mu.shape: torch.Size([4, 7, 784]), P_sigma.shape: torch.Size([4, 7, 784, 784])\n",
      "z.shape:  torch.Size([7, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#Extract a single batch\n",
    "for images, digits in train_loader:\n",
    "    break\n",
    "\n",
    "#Initialise hyperarameters\n",
    "n_observed = images.shape[-1]\n",
    "n_latent = 5\n",
    "f_hidden_sizes = [10, 12]\n",
    "Q_hidden_sizes = [20, 24, 28]\n",
    "sigma = 1\n",
    "z_batch_size = 7\n",
    "\n",
    "test_model = VAE(n_observed, n_latent, f_hidden_sizes, Q_hidden_sizes, z_batch_size)\n",
    "\n",
    "#Test full model\n",
    "Q_mu, Q_sigma, z, P_mu, P_sigma = test_model(images, skip_encode = False)\n",
    "print(f\"Q_mu.shape: {Q_mu.shape}, Q_sigma.shape: {Q_sigma.shape}, z.shape: {z.shape}, P_mu.shape: {P_mu.shape}, P_sigma.shape: {P_sigma.shape}\")\n",
    "\n",
    "#Test only decder\n",
    "z = torch.distributions.MultivariateNormal(torch.zeros(n_latent), torch.eye(n_latent)).sample((z_batch_size, n_latent))\n",
    "print(\"z.shape: \", z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Train and Evaluate VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def train_VAE(train_loader, model, n_epochs, optimiser):\n",
    "  \"\"\"\n",
    "  Function to train the VAE.\n",
    "\n",
    "  Inputs:\n",
    "  - train_loader: the `DataLoader` object for the training dataset.\n",
    "  - model: the VAE model to be trained.\n",
    "  - n_epochs: number of times to loop through entire dataset during optimisation.\n",
    "  \n",
    "  Outputs:\n",
    "  - model: trained VAE model.\n",
    "  - loss: total training loss for the model\n",
    "  \"\"\"\n",
    "\n",
    "  #Initialise variables\n",
    "  n_batches = len(train_loader)\n",
    "  batch_sizes = [len(batch) for batch in train_loader]\n",
    "  loss_by_epoch = [0 for _ in range(n_epochs)]\n",
    "  #Only want to print every 10% per epoch\n",
    "  checkpoints = [torch.ceil(torch.tensor(n_batches/10) * (i)) for i in range(10+1)]\n",
    "  i = 0\n",
    "\n",
    "  #Loop through entire dataset the specified number of times\n",
    "  for epoch_index in range(n_epochs):\n",
    "    for batch_index, (images, digits) in enumerate(train_loader):\n",
    "      #Compute loss\n",
    "      z, Q_mu, Q_sigma, P_mu, P_sigma = model(images, skip_encode = False)\n",
    "      batch_loss = torch.sum(loss_per_batch(images, z, Q_mu, Q_sigma, P_mu, P_sigma))\n",
    "      loss_by_epoch[epoch_index] += batch_loss\n",
    "      \n",
    "      #Update parameters based on optimiser\n",
    "      optimiser.zero_grad()\n",
    "      batch_loss.backward()\n",
    "      optimiser.step()\n",
    "\n",
    "      #Only print occasional batch statistics\n",
    "      if batch_index == checkpoints[i]:\n",
    "        print(f\"Batch number: {batch_index}/{n_batches}. Average batch loss: {batch_loss / batch_sizes[batch_index]}\")\n",
    "        i += 1\n",
    "        \n",
    "  print(f\"\\n\\nEpoch number: {epoch_index}/{n_epochs}. Total epoch loss: {loss_by_epoch[epoch_index]}.\\nEpoch loss history: {loss_by_epoch}\\n\\n\")\n",
    "\n",
    "  return model, loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_VAE(test_loader, model, loss_history):\n",
    "  \"\"\"\n",
    "  Function to test the VAE.\n",
    "\n",
    "  Inputs:\n",
    "  - test_loader: the `DataLoader` object for the testing dataset.\n",
    "  - model: the VAE model to be trained.\n",
    "  - loss_history: a list of previous test losses (to be able to print the historical loss).\n",
    "\n",
    "  Outputs:\n",
    "  - loss: total training loss for the model\n",
    "  \"\"\"\n",
    "\n",
    "  #Initialise variables\n",
    "  loss = 0\n",
    "\n",
    "  #Loop through dataset\n",
    "  for batch_index, (images, digits) in enumerate(train_loader):      \n",
    "      #Compute loss\n",
    "      z, Q_mu, Q_sigma, P_mu, P_sigma = model(images, skip_encode = False)\n",
    "      batch_loss = torch.sum(loss_per_batch(images, z, Q_mu, Q_sigma, P_mu, P_sigma))\n",
    "      loss += batch_loss\n",
    "\n",
    "  print(f\"\\n\\nTest loss: {loss}.\\nTest loss history: {loss_history.append(loss)}\\n\\n\")\n",
    "\n",
    "  return loss\n",
    "\n",
    "\n",
    "def objective(trial, train_loader, test_loader, n_latent, z_batch_size, n_epochs, loss_history):\n",
    "  \"\"\"  \n",
    "  Objective function for Optuna to optimise. Here, hyperparameters are suggested by the package.\n",
    "  \n",
    "  Inputs:\n",
    "  - trial: optuna.trial.Trial object\n",
    "  - train_loader & test_loader: dataloaders for the training and testing datasets.\n",
    "  - n_latent: number of latent variables for each data point.\n",
    "  - z_batch_size: number of latent samples per data point to compute gradient.\n",
    "  - n_epochs: number of times to loop through entire dataset.\n",
    "  - loss_history: a list of previous test losses (to be able to print the historical loss).\n",
    "\n",
    "  Outputs:\n",
    "  - loss: scalar value for the loss across the entire test dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  #Suggest hyperparameters\n",
    "  n_latent = trial.suggest_int(\"n_latent\", 5, 50)\n",
    "  f_n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "  Q_n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "  #We will start with all layers having equal size\n",
    "  f_hidden_size = trial.suggest_int(\"hidden_size\", 32, 128)\n",
    "  Q_hidden_size = trial.suggest_int(\"hidden_size\", 32, 128)\n",
    "  learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "  #dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "\n",
    "  #Initialise variables and other hyperparameters\n",
    "  f_hidden_sizes = [f_hidden_size for _ in range(f_n_layers)]\n",
    "  Q_hidden_sizes = [Q_hidden_size for _ in range(Q_n_layers)]\n",
    "  for (images, digits) in train_loader:\n",
    "    break\n",
    "  #Number of observed variables is product of all dimension lengths except first (batch)\n",
    "  n_observed = torch.prod(torch.tensor(images[(0,) + (slice(None),) * (images.dim() - 1)].shape))\n",
    "\n",
    "  #Initialise model and optimiser\n",
    "  model = VAE(n_observed, n_latent, f_hidden_sizes, Q_hidden_sizes, z_batch_size)\n",
    "  optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  #Train model\n",
    "  model, _ = train_VAE(train_loader, model, n_epochs, optimiser)\n",
    "\n",
    "  #Test model\n",
    "  loss = test_VAE(test_loader, model, loss_history)\n",
    "  loss_history.append(loss)\n",
    "\n",
    "  return loss\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-17 07:46:11,096] A new study created in memory with name: no-name-777324a1-e32a-4e3e-9adf-f0cd5d773b02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints:  [tensor(0.), tensor(1500.), tensor(3000.), tensor(4500.), tensor(6000.), tensor(7500.), tensor(9000.), tensor(10500.), tensor(12000.), tensor(13500.)]\n",
      "Batch number: 0/15000. Average batch loss: 2218.64208984375\n",
      "Batch number: 1500/15000. Average batch loss: 2169.84423828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-17 07:51:59,334] Trial 0 failed with parameters: {'n_latent': 47, 'n_layers': 3, 'hidden_size': 32, 'lr': 0.0024357293573215037} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\kperc\\AppData\\Local\\Temp\\ipykernel_45484\\2390069452.py\", line 11, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, train_loader, test_loader, n_latent, z_batch_size, n_epochs, loss_history), n_trials=100)\n",
      "                                 ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kperc\\AppData\\Local\\Temp\\ipykernel_45484\\3003194568.py\", line 118, in objective\n",
      "    model, _ = train_VAE(train_loader, model, n_epochs, optimiser)\n",
      "               ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kperc\\AppData\\Local\\Temp\\ipykernel_45484\\3003194568.py\", line 36, in train_VAE\n",
      "    batch_loss.backward()\n",
      "    ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 353, in backward\n",
      "    _engine_run_backward(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        tensors,\n",
      "        ^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        accumulate_grad=True,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 824, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        t_outputs, *args, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )  # Calls into the C++ engine to run the backward pass\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-17 07:51:59,337] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[305]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Run the study\u001b[39;00m\n\u001b[32m     10\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_history\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Best result\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[305]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Run the study\u001b[39;00m\n\u001b[32m     10\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_history\u001b[49m\u001b[43m)\u001b[49m, n_trials=\u001b[32m100\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Best result\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[304]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial, train_loader, test_loader, n_latent, z_batch_size, n_epochs, loss_history)\u001b[39m\n\u001b[32m    115\u001b[39m optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m#Train model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m model, _ = \u001b[43mtrain_VAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m#Test model\u001b[39;00m\n\u001b[32m    121\u001b[39m loss = test_VAE(test_loader, model, loss_history)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[304]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain_VAE\u001b[39m\u001b[34m(train_loader, model, n_epochs, optimiser)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#Update parameters based on optimiser\u001b[39;00m\n\u001b[32m     35\u001b[39m optimiser.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mbatch_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m optimiser.step()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m#Only print occasional batch statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kperc\\VAE\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Initialise hyperparameters\n",
    "for (images, digits) in train_loader:\n",
    "    break\n",
    "batch_size = images.shape[0]\n",
    "z_batch_size = 1\n",
    "n_epochs = 10\n",
    "loss_history = []\n",
    "\n",
    "# Run the study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lambda trial: objective(trial, train_loader, test_loader, n_latent, z_batch_size, n_epochs, loss_history), n_trials=100)\n",
    "\n",
    "# Best result\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(f\"  Params: {trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfjEK2ePMHON"
   },
   "source": [
    "## Notes\n",
    "\n",
    "- Will use $P(X|z) = N(X|f(z; \\theta), \\sigma^2 * I)$ for a loss function. We wish to maximise this, or equivalently to minimise $-P(X|z)$.\n",
    "- Could simplify by only feeding through distributions to loss function and leaving it to Pytorch to compute KL-divergence. This would be very simple and allows generalisation to non-normal distributions.\n",
    "- We will start by minimising $\\sigma^2$ as a global parameter, like in the textbook \"Understanding \n",
    "Deep Learning\". But, could improve this in the future.\n",
    "- Currently estimating $\\mu(X; \\phi)$ and $\\Sigma(X; \\phi)$ through a single neural network, although\n",
    "could separate this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - basic\n",
    "- Check: we have to sample z from Q before we can actually train the neural network f, right?\n",
    "- Consider how to optimise sigma globally in practice.\n",
    "- Must add function to ensure that output of VAE is in the correct form, i.e. a picture of integers between 0 and 255?\n",
    "- Add dropout or some other bells and whistles?\n",
    "\n",
    "### TODO - future\n",
    "- Add preprocessing - is it best practice to standardise variables to have mean 0 and variance 1?\n",
    "- Add conditional VAE theory\n",
    "- Add recent research in Beta-Sigma VAE: https://arxiv.org/pdf/2409.09361"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
